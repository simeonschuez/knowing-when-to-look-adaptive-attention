{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vu48pok/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_karpathy_split, get_refcoco_captions\n",
    "from data_loader_captions import get_caption_loader, get_reg_loader\n",
    "from build_vocab import Vocabulary\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = '/home/vu48pok/.data/compling/data/corpora/external/MSCOCO/COCO/splits/karpathy/caption_datasets/'\n",
    "caps_path = '/home/vu48pok/.data/compling/data/corpora/external/MSCOCO/COCO/'\n",
    "image_dir = '/home/vu48pok/.data/compling/data/corpora/external/MSCOCO/COCO/'\n",
    "crop_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((crop_size, crop_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                             (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = get_refcoco_captions('/home/vu48pok/.data/compling/data/corpora/external/COCO_ReferIt/licheng/refcoco/')\n",
    "\n",
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf47e98ba6394f3b82991f8b854f3e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120624.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_caps = reg_df.loc[reg_df.split == 'train'].caption.to_list()\n",
    "words = []\n",
    "\n",
    "for c in tqdm(train_caps):\n",
    "    c = c.casefold()\n",
    "    c = c.translate(str.maketrans('', '', punctuation))\n",
    "    words += nltk.word_tokenize(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w, cnt in words_count.items() if cnt >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words_count = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words_count:\n",
    "    if words_count[w] >= 3:\n",
    "        vocab.add_word(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4860c732750d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_refcoco_captions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/vu48pok/.data/compling/data/corpora/external/COCO_ReferIt/licheng/refcoco/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/Projekte/reg/knowing-when-to-look-adaptive-attention/data_utils.py\u001b[0m in \u001b[0;36mget_refcoco_captions\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instances.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/local/.anaconda/envs/spacy/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/local/.anaconda/envs/spacy/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg_df = get_refcoco_captions('/home/vu48pok/.data/compling/data/corpora/external/COCO_ReferIt/licheng/refcoco/')\n",
    "\n",
    "vocab = Vocabulary()\n",
    "\n",
    "vocab.add_word('<pad>')\n",
    "vocab.add_word('<start>')\n",
    "vocab.add_word('<end>')\n",
    "vocab.add_word(vocab.unknown_token)\n",
    "\n",
    "train_caps = reg_df.loc[reg_df.split == 'train'].caption.to_list()\n",
    "for c in tqdm(train_caps[:1000]):\n",
    "    c = c.casefold()\n",
    "    c = c.translate(str.maketrans('', '', punctuation))\n",
    "    for t in nltk.word_tokenize(c):\n",
    "        vocab.add_word(t)\n",
    "        \n",
    "reg_loader = get_reg_loader(\n",
    "    decoding_level='word', \n",
    "    split='train',\n",
    "    data_df=reg_df, \n",
    "    image_dir=image_dir, \n",
    "    vocab=vocab,\n",
    "    transform=transform, \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    num_workers=2, \n",
    "    drop_last=False   \n",
    ")\n",
    "\n",
    "for i, data in enumerate(reg_loader):\n",
    "    d = data\n",
    "    if i > 0:\n",
    "        break\n",
    "    \n",
    "images, targets, pos_features, lengths = d\n",
    "\n",
    "for t in targets[:,1:]:\n",
    "    print(' '.join([vocab.idx2word[i.item()] for i in t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe073590c6dc4a4590a2f5eb43d6012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a kitchen with a tile floor has cabinets with no doors a dishwasher a sink and a refrigerator <end>\n",
      "photo of a man riding an old styled bicycle near what appears to be the golden gate bridge <end>\n",
      "a purple bus and a man dressed as a nun on a tall bicycle <end> <pad> <pad> <pad> <pad>\n",
      "a man working at a kitchen counter in a room illuminated by sunlight <end> <pad> <pad> <pad> <pad> <pad>\n",
      "a black cat making an angry face while sitting on the bathroom floor <end> <pad> <pad> <pad> <pad> <pad>\n",
      "a person on a bicycle is riding in front of a car <end> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "there is some pet food in the floor in an empty kitchen <end> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "the top of a kitchen cabinet covered with brass pots and pans <end> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a woman is shaving her face while sitting on a wooden bench <end> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a cat peeking out a car window that is rolled down <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a closeup of a red fire hydrant including the chains <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a man standing in the kitchen with his arms crossed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "an herb that is in front of a toaster oven <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "clean bathroom that is brightly colored and has a window <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "people standing around many silver round balls on the ground <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "seagulls flying overhead while trucks sit in a parking lot <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "the sky is full of colorful kites along a mountain <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "two teenagers at a white sanded beach with surfboards <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "clean indoor bathroom with tiled floor and good lighting <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "lady carrying a purse walking along side a man <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a wide angle view of the kitchen work area <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a man standing in a kitchen with granite countertops <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a modern bathroom contains many glass and tile pieces <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a clean mediocre motel bathroom with a nice sink <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a kitchen counter is illuminated by a hood light <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a public restroom toilet has been photographed in sepia <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a surfer riding his bike to the beach <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a skinny horse is grazing in a field <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a demonstration of a well maintained hotel bathroom <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a city sidewalk is lined with lamp posts <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a bathroom with a tv near the mirror <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "a young boy surfing in low waves <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "caps_df = get_karpathy_split(splits_path=splits_path, caps_path=caps_path)\n",
    "\n",
    "vocab = Vocabulary()\n",
    "\n",
    "vocab.add_word('<pad>')\n",
    "vocab.add_word('<start>')\n",
    "vocab.add_word('<end>')\n",
    "vocab.add_word(vocab.unknown_token)\n",
    "\n",
    "train_caps = caps_df.loc[caps_df.split == 'train'].caption.to_list()\n",
    "for c in tqdm(train_caps[:1000]):\n",
    "    c = c.casefold()\n",
    "    c = c.translate(str.maketrans('', '', punctuation))\n",
    "    for t in nltk.word_tokenize(c):\n",
    "        vocab.add_word(t)\n",
    "        \n",
    "caps_loader = get_caption_loader(\n",
    "    decoding_level='word', \n",
    "    split='train',\n",
    "    data_df=caps_df, \n",
    "    image_dir=image_dir, \n",
    "    vocab=vocab,\n",
    "    transform=transform, \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    num_workers=2, \n",
    "    drop_last=False   \n",
    ")\n",
    "\n",
    "for i, data in enumerate(caps_loader):\n",
    "    d = data\n",
    "    if i > 0:\n",
    "        break\n",
    "    \n",
    "images, targets, lengths = d\n",
    "\n",
    "for t in targets[:,1:]:\n",
    "    print(' '.join([vocab.idx2word[i.item()] for i in t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
